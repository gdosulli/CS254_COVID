{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Load in pneumonia/healthy data to train CNN on\n",
    "\n",
    "We will be training a CNN with a large pneumonia/healthy chest x-ray dataset and use transfer learning to train it for COVID/Non-COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_d = {'filename': [], 'target': []}\n",
    "\n",
    "# format: (file location, healthy/pneumonia(0/1))\n",
    "files = [('train/Normal', 0), \n",
    "         ('train/Pneumonia', 1),\n",
    "         ('test/Normal', 0), \n",
    "         ('test/Pneumonia', 1),\n",
    "         ('val/Normal', 0), \n",
    "         ('val/Pneumonia', 1),]\n",
    "\n",
    "for file in files:\n",
    "    dir_path = os.path.abspath(os.getcwd())\n",
    "    dir_path = dir_path + \"/chest_xray/\" + file[0]\n",
    "    list = os.listdir(dir_path)\n",
    "    for pic in list:\n",
    "        if '.DS_Store' not in pic:\n",
    "            init_d['filename'].append(pic)\n",
    "            init_d['target'].append(file[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Preprocessing for images\n",
    "Load in images for the corresponding target data with PIL. Reformat all images to the same dimensions and convert them to a numpy array for the models to use (where each is a (# pixels, # pixels) array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in image data from filenames with PIL\n",
    "img_dim = 128\n",
    "def normalize_images(d, curr_dir):\n",
    "    \"\"\"normalize all images inside dictionary\"\"\"\n",
    "    images = np.empty((len(d['target']), img_dim, img_dim, 2))\n",
    "\n",
    "    for i in range(len(d['filename'])):\n",
    "        image = Image.open(curr_dir + d['filename'][i])\n",
    "\n",
    "        # resize image shape\n",
    "        image = image.resize((img_dim, img_dim))\n",
    "\n",
    "        # convert to grayscale\n",
    "        image = image.convert('LA')\n",
    "\n",
    "        images[i] = np.array(image)\n",
    "\n",
    "    # normalize values\n",
    "    images = images / 255.0\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train/test/val images\n",
    "images = normalize_images(init_d, \"chest_xray/pooled_imgs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Train Pneumonia/Healthy Classifier with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, init_d['target'], test_size=0.25, random_state=0)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 126, 126, 32)      608       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                3211328   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,267,490\n",
      "Trainable params: 3,267,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model for convolutional network\n",
    "cnn_model = models.Sequential()\n",
    "cnn_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_dim, img_dim, 2)))\n",
    "cnn_model.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# add more layers\n",
    "cnn_model.add(layers.Flatten())\n",
    "cnn_model.add(layers.Dense(64, activation='relu'))\n",
    "cnn_model.add(layers.Dense(2))\n",
    "\n",
    "# compile \n",
    "cnn_model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "138/138 [==============================] - 45s 325ms/step - loss: 0.2925 - accuracy: 0.8818 - val_loss: 0.2860 - val_accuracy: 0.8736\n",
      "Epoch 2/10\n",
      "138/138 [==============================] - 49s 352ms/step - loss: 0.1884 - accuracy: 0.9308 - val_loss: 0.1790 - val_accuracy: 0.9385\n",
      "Epoch 3/10\n",
      "138/138 [==============================] - 51s 370ms/step - loss: 0.1623 - accuracy: 0.9385 - val_loss: 0.1967 - val_accuracy: 0.9392\n",
      "Epoch 4/10\n",
      "138/138 [==============================] - 47s 342ms/step - loss: 0.1507 - accuracy: 0.9447 - val_loss: 0.1613 - val_accuracy: 0.9372\n",
      "Epoch 5/10\n",
      "138/138 [==============================] - 47s 338ms/step - loss: 0.1382 - accuracy: 0.9495 - val_loss: 0.1463 - val_accuracy: 0.9508\n",
      "Epoch 6/10\n",
      "138/138 [==============================] - 50s 364ms/step - loss: 0.1325 - accuracy: 0.9474 - val_loss: 0.1396 - val_accuracy: 0.9447\n",
      "Epoch 7/10\n",
      "138/138 [==============================] - 47s 340ms/step - loss: 0.1208 - accuracy: 0.9570 - val_loss: 0.1576 - val_accuracy: 0.9454\n",
      "Epoch 8/10\n",
      "138/138 [==============================] - 45s 329ms/step - loss: 0.1158 - accuracy: 0.9567 - val_loss: 0.1429 - val_accuracy: 0.9481\n",
      "Epoch 9/10\n",
      "138/138 [==============================] - 55s 396ms/step - loss: 0.1046 - accuracy: 0.9620 - val_loss: 0.1598 - val_accuracy: 0.9501\n",
      "Epoch 10/10\n",
      "138/138 [==============================] - 58s 422ms/step - loss: 0.1019 - accuracy: 0.9577 - val_loss: 0.1518 - val_accuracy: 0.9474\n"
     ]
    }
   ],
   "source": [
    "history = cnn_model.fit(x_train, y_train, epochs=10,\n",
    "                       validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Load in COVID Data\n",
    "\n",
    "Read in csv of metadata for the images and select target data. For our target data we are selecting COVID/Non-COVID, Survival, Intubation, and Admission to the ICU - resulting in 28 classes where class 0 = Non-COVID and class > 0 is COVID and some unique combination of the classes above. For the initial training and testing of this data, any class > 0 we set to 1 to train a binary classifier for COVID/Non-COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[279, 4, 3, 0, 0, 48, 0, 3, 6, 79, 8, 8, 2, 0, 1, 1, 0, 0, 18, 45, 31, 8, 0, 9, 0, 5, 225, 0]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(\"metadata.csv\") as file:\n",
    "    for row in csv.reader(file):\n",
    "        data.append(row)\n",
    "\n",
    "data = data[1:]\n",
    "\n",
    "d = {'filename': [], 'target': []}\n",
    "\n",
    "for image in data:\n",
    "    # skip volume data\n",
    "    if image[22] == \"volumes\":\n",
    "        continue\n",
    "    \n",
    "    # ignore CT scan data\n",
    "    if image[19] == \"CT\":\n",
    "        continue\n",
    "    \n",
    "    diagnosis = image[4].split(\"/\")\n",
    "    diagnosis = diagnosis[len(diagnosis) - 1].lower()\n",
    "    # set target based on meta data\n",
    "    if diagnosis != \"covid-19\":\n",
    "        if diagnosis == \"todo\":\n",
    "            # if not classified yet target = -1\n",
    "            # d['filename'].append(image[23])\n",
    "            # d['target'].append(-1)\n",
    "            # ignore unknown data\n",
    "            continue\n",
    "        else:\n",
    "            # if not COVID-19 target = 0\n",
    "            d['filename'].append(image[23])\n",
    "            d['target'].append(0)\n",
    "    else:\n",
    "        # if it is COVID-19\n",
    "        if image[6] == \"Y\":\n",
    "            # if they survived\n",
    "            if image[7] == \"Y\":\n",
    "                # if they were intubated\n",
    "                if image[8] == \"Y\":\n",
    "                    # if they were put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(1)\n",
    "                elif image[8] == \"N\":\n",
    "                    # if they were not put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(2)\n",
    "                else:\n",
    "                    # if they were put in the icu is unknown\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(3)\n",
    "            elif image[7] == \"N\":\n",
    "                # if they were not intubated\n",
    "                if image[8] == \"Y\":\n",
    "                    # if they were put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(4)\n",
    "                elif image[8] == \"N\":\n",
    "                    # if they were not put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(5)\n",
    "                else:\n",
    "                    # if they were put in the icu is unknown\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(6)\n",
    "            else:\n",
    "                # if they were intubated is unknown\n",
    "                if image[8] == \"Y\":\n",
    "                    # if they were put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(7)\n",
    "                elif image[8] == \"N\":\n",
    "                    # if they were not put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(8)\n",
    "                else:\n",
    "                    # if they were put in the icu is unknown\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(9)\n",
    "        elif image[6] == \"N\":\n",
    "            # if they did not survive\n",
    "            if image[7] == \"Y\":\n",
    "                # if they were intubated\n",
    "                if image[8] == \"Y\":\n",
    "                    # if they were put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(10)\n",
    "                elif image[8] == \"N\":\n",
    "                    # if they were not put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(11)\n",
    "                else:\n",
    "                    # if they were put in the icu is unknown\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(12)\n",
    "            elif image[7] == \"N\":\n",
    "                # if they were not intubated\n",
    "                if image[8] == \"Y\":\n",
    "                    # if they were put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(13)\n",
    "                elif image[8] == \"N\":\n",
    "                    # if they were not put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(14)\n",
    "                else:\n",
    "                    # if they were put in the icu is unknown\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(15)\n",
    "            else:\n",
    "                # if they were intubated is unknown\n",
    "                if image[8] == \"Y\":\n",
    "                    # if they were put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(16)\n",
    "                elif image[8] == \"N\":\n",
    "                    # if they were not put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(17)\n",
    "                else:\n",
    "                    # if they were put in the icu is unknown\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(18)\n",
    "        else:\n",
    "            # if their survival is unknown\n",
    "            if image[7] == \"Y\":\n",
    "                # if they were intubated\n",
    "                if image[8] == \"Y\":\n",
    "                    # if they were put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(19)\n",
    "                elif image[8] == \"N\":\n",
    "                    # if they were not put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(20)\n",
    "                else:\n",
    "                    # if they were put in the icu is unknown\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(21)\n",
    "            elif image[7] == \"N\":\n",
    "                # if they were not intubated\n",
    "                if image[8] == \"Y\":\n",
    "                    # if they were put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(22)\n",
    "                elif image[8] == \"N\":\n",
    "                    # if they were not put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(23)\n",
    "                else:\n",
    "                    # if they were put in the icu is unknown\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(23)\n",
    "            else:\n",
    "                # if they were intubated is unknown\n",
    "                if image[8] == \"Y\":\n",
    "                    # if they were put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(24)\n",
    "                elif image[8] == \"N\":\n",
    "                    # if they were not put in the icu\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(25)\n",
    "                else:\n",
    "                    # if they were put in the icu is unknown\n",
    "                    d['filename'].append(image[23])\n",
    "                    d['target'].append(26)\n",
    "total = [0] * 28\n",
    "for target in d['target']:\n",
    "    if target == -1:\n",
    "        total[27] += 1\n",
    "    else:\n",
    "        total[target] += 1\n",
    "\n",
    "# set up binary classification (covid vs non-covid)\n",
    "# all targets > 0 are covid\n",
    "for i in range(len(d['target'])):\n",
    "    if d['target'][i] > 0:\n",
    "        d['target'][i] = 1\n",
    "\n",
    "print(total)\n",
    "#print(d)\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess covid/noncovid images\n",
    "covid_images = normalize_images(d, \"model_images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Train COVID/Non-COVID with Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(covid_images, d['target'], test_size=0.25, random_state=0)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weights from outer model\n",
    "all_weights = []\n",
    "for layer in cnn_model.layers:\n",
    "   w = layer.get_weights()\n",
    "   all_weights.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model = cnn_model\n",
    "\n",
    "temp_model.layers.pop()\n",
    "\n",
    "covid_model = temp_model\n",
    "\n",
    "covid_model.add(layers.Dense(2))\n",
    "\n",
    "covid_model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "138/138 [==============================] - 46s 333ms/step - loss: 0.1049 - accuracy: 0.9620 - val_loss: 0.1631 - val_accuracy: 0.9501\n",
      "Epoch 2/10\n",
      "138/138 [==============================] - 45s 325ms/step - loss: 0.0768 - accuracy: 0.9695 - val_loss: 0.1622 - val_accuracy: 0.9488\n",
      "Epoch 3/10\n",
      "138/138 [==============================] - 43s 313ms/step - loss: 0.0733 - accuracy: 0.9715 - val_loss: 0.1612 - val_accuracy: 0.9495\n",
      "Epoch 4/10\n",
      "138/138 [==============================] - 51s 370ms/step - loss: 0.0582 - accuracy: 0.9781 - val_loss: 0.2484 - val_accuracy: 0.9460\n",
      "Epoch 5/10\n",
      "138/138 [==============================] - 54s 388ms/step - loss: 0.0465 - accuracy: 0.9827 - val_loss: 0.2386 - val_accuracy: 0.9242\n",
      "Epoch 6/10\n",
      "138/138 [==============================] - 50s 365ms/step - loss: 0.0558 - accuracy: 0.9795 - val_loss: 0.1711 - val_accuracy: 0.9515\n",
      "Epoch 7/10\n",
      "138/138 [==============================] - 37s 268ms/step - loss: 0.0327 - accuracy: 0.9872 - val_loss: 0.2401 - val_accuracy: 0.9508\n",
      "Epoch 8/10\n",
      "138/138 [==============================] - 36s 264ms/step - loss: 0.0262 - accuracy: 0.9900 - val_loss: 0.2101 - val_accuracy: 0.9474\n",
      "Epoch 9/10\n",
      "138/138 [==============================] - 37s 265ms/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 0.1922 - val_accuracy: 0.9440\n",
      "Epoch 10/10\n",
      "138/138 [==============================] - 37s 265ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.2482 - val_accuracy: 0.9481\n"
     ]
    }
   ],
   "source": [
    "covid_history = covid_model.fit(x_train, y_train, epochs=10,\n",
    "                              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
